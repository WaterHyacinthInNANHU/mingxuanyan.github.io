<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>

<style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color:#ffffff; --text-color:#333333; --select-text-bg-color:#B5D6FC; --select-text-font-color:auto; --monospace:"Lucida Console",Consolas,"Courier",monospace; --title-bar-height:20px; }
.mac-os-11 { --title-bar-height:28px; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
h1, h2, h3, h4, h5 { white-space: pre-wrap; }
body { margin: 0px; padding: 0px; height: auto; inset: 0px; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; tab-size: 4; }
iframe { margin: auto; }
a.url { word-break: break-all; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; overflow-wrap: break-word; position: relative; white-space: normal; overflow-x: visible; padding-top: 36px; }
#write.first-line-indent p { text-indent: 2em; }
#write.first-line-indent li p, #write.first-line-indent p * { text-indent: 0px; }
#write.first-line-indent li { margin-left: 2em; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
.typora-export .footnote-line, .typora-export li, .typora-export p { white-space: pre-wrap; }
.typora-export .task-list-item input { pointer-events: none; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  #write { padding-left: 20px; padding-right: 20px; }
}
#write li > figure:last-child { margin-bottom: 0.5rem; }
#write ol, #write ul { position: relative; }
img { max-width: 100%; vertical-align: middle; image-orientation: from-image; }
button, input, select, textarea { color: inherit; font: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; }
p { line-height: inherit; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 4; }
p { orphans: 4; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px; }
thead, tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 32px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror-linenumber { user-select: none; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
#write pre { white-space: pre-wrap; }
#write.fences-no-line-wrapping pre { white-space: pre; }
#write pre.ty-contain-cm { white-space: normal; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: inherit; position: relative !important; }
.md-fences-adv-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
#write .md-fences.mock-cm { white-space: pre-wrap; }
.md-fences.md-fences-with-lineno { padding-left: 0px; }
#write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; }
.md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; }
.CodeMirror-line, twitterwidget { break-inside: avoid; }
svg { break-inside: avoid; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: 0px 0px; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li blockquote { margin: 1rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
#write .footnote-line { white-space: pre-wrap; }
@media print {
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; font-variant-ligatures: no-common-ligatures; }
  #write { margin-top: 0px; border-color: transparent !important; padding-top: 0px !important; padding-bottom: 0px !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  .typora-export #write { break-after: avoid; }
  .typora-export #write::after { height: 0px; }
  .is-mac table { break-inside: avoid; }
  #write > p:nth-child(1) { margin-top: 0px; }
  .typora-export-show-outline .typora-export-sidebar { display: none; }
  figure { overflow-x: visible; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p > .md-image:only-child:not(.md-img-error) img, p > img:only-child { display: block; margin: auto; }
#write.first-line-indent p > .md-image:only-child:not(.md-img-error) img { left: -2em; position: relative; }
p > .md-image:only-child { display: inline-block; width: 100%; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.md-math-block { width: 100%; }
.md-math-block:not(:empty)::after { display: none; }
.MathJax_ref { fill: currentcolor; }
[contenteditable="true"]:active, [contenteditable="true"]:focus, [contenteditable="false"]:active, [contenteditable="false"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); border: none; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-content::after, .md-toc::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { text-decoration: underline; }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.reversefootnote { font-family: ui-monospace, sans-serif; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, samp, tt { font-family: var(--monospace); }
kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.6; font-family: var(--monospace); }
code { text-align: left; vertical-align: initial; }
a.md-print-anchor { white-space: pre !important; border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; background: 0px 0px !important; text-decoration: initial !important; text-shadow: initial !important; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; height: auto; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom: 0px; }
video { max-width: 100%; display: block; margin: 0px auto; }
iframe { max-width: 100%; width: 100%; border: none; }
.highlight td, .highlight tr { border: 0px; }
mark { background: rgb(255, 255, 0); color: rgb(0, 0, 0); }
.md-html-inline .md-plain, .md-html-inline strong, mark .md-inline-math, mark strong { color: inherit; }
.md-expand mark .md-meta { opacity: 0.3 !important; }
mark .md-meta { color: rgb(0, 0, 0); }
@media print {
  .typora-export h1, .typora-export h2, .typora-export h3, .typora-export h4, .typora-export h5, .typora-export h6 { break-inside: avoid; }
}
.md-diagram-panel .messageText { stroke: none !important; }
.md-diagram-panel .start-state { fill: var(--node-fill); }
.md-diagram-panel .edgeLabel rect { opacity: 1 !important; }
.md-fences.md-fences-math { font-size: 1em; }
.md-fences-advanced:not(.md-focus) { padding: 0px; white-space: nowrap; border: 0px; }
.md-fences-advanced:not(.md-focus) { background: inherit; }
.typora-export-show-outline .typora-export-content { max-width: 1440px; margin: auto; display: flex; flex-direction: row; }
.typora-export-sidebar { width: 300px; font-size: 0.8rem; margin-top: 80px; margin-right: 18px; }
.typora-export-show-outline #write { --webkit-flex:2; flex: 2 1 0%; }
.typora-export-sidebar .outline-content { position: fixed; top: 0px; max-height: 100%; overflow: hidden auto; padding-bottom: 30px; padding-top: 60px; width: 300px; }
@media screen and (max-width: 1024px) {
  .typora-export-sidebar, .typora-export-sidebar .outline-content { width: 240px; }
}
@media screen and (max-width: 800px) {
  .typora-export-sidebar { display: none; }
}
.outline-content li, .outline-content ul { margin-left: 0px; margin-right: 0px; padding-left: 0px; padding-right: 0px; list-style: none; overflow-wrap: anywhere; }
.outline-content ul { margin-top: 0px; margin-bottom: 0px; }
.outline-content strong { font-weight: 400; }
.outline-expander { width: 1rem; height: 1.42857rem; position: relative; display: table-cell; vertical-align: middle; cursor: pointer; padding-left: 4px; }
.outline-expander::before { content: ""; position: relative; font-family: Ionicons; display: inline-block; font-size: 8px; vertical-align: middle; }
.outline-item { padding-top: 3px; padding-bottom: 3px; cursor: pointer; }
.outline-expander:hover::before { content: ""; }
.outline-h1 > .outline-item { padding-left: 0px; }
.outline-h2 > .outline-item { padding-left: 1em; }
.outline-h3 > .outline-item { padding-left: 2em; }
.outline-h4 > .outline-item { padding-left: 3em; }
.outline-h5 > .outline-item { padding-left: 4em; }
.outline-h6 > .outline-item { padding-left: 5em; }
.outline-label { cursor: pointer; display: table-cell; vertical-align: middle; text-decoration: none; color: inherit; }
.outline-label:hover { text-decoration: underline; }
.outline-item:hover { border-color: rgb(245, 245, 245); background-color: var(--item-hover-bg-color); }
.outline-item:hover { margin-left: -28px; margin-right: -28px; border-left: 28px solid transparent; border-right: 28px solid transparent; }
.outline-item-single .outline-expander::before, .outline-item-single .outline-expander:hover::before { display: none; }
.outline-item-open > .outline-item > .outline-expander::before { content: ""; }
.outline-children { display: none; }
.info-panel-tab-wrapper { display: none; }
.outline-item-open > .outline-children { display: block; }
.typora-export .outline-item { padding-top: 1px; padding-bottom: 1px; }
.typora-export .outline-item:hover { margin-right: -8px; border-right: 8px solid transparent; }
.typora-export .outline-expander::before { content: "+"; font-family: inherit; top: -1px; }
.typora-export .outline-expander:hover::before, .typora-export .outline-item-open > .outline-item > .outline-expander::before { content: "−"; }
.typora-export-collapse-outline .outline-children { display: none; }
.typora-export-collapse-outline .outline-item-open > .outline-children, .typora-export-no-collapse-outline .outline-children { display: block; }
.typora-export-no-collapse-outline .outline-expander::before { content: "" !important; }
.typora-export-show-outline .outline-item-active > .outline-item .outline-label { font-weight: 700; }
.md-inline-math-container mjx-container { zoom: 0.95; }
mjx-container { break-inside: avoid; }


html {
	font-size: 19px;
}

html, body {
	margin: auto;
	background: #fefefe;
	-webkit-font-smoothing: antialiased;
}
body {
	font-family: "Vollkorn", Palatino, Times;
	color: #333;
	line-height: 1.4;
	text-align: justify;
}

#write {
	max-width: 960px;
	margin: 0 auto;
	margin-bottom: 2em;
	line-height: 1.53;
	padding-top: 40px;
}

@media only screen and (min-width: 1400px) {
	#write {
		max-width: 1100px;
	}
}

@media print {
	html {
		font-size: 13px;
	}
}

/* Typography
-------------------------------------------------------- */

#write>h1:first-child,
h1 {
	margin-top: 1.6em;
	font-weight: normal;
}

h1 {
	font-size:3em;
}

h2 {
	margin-top:2em;
	font-weight: normal;
}

h3 {
	font-weight: normal;
	font-style: italic;
	margin-top: 3em;
}

h1, 
h2, 
h3{
	text-align: center;
}

h2:after{
	border-bottom: 1px solid #2f2f2f;
    content: '';
    width: 100px;
    display: block;
    margin: 0 auto;
    height: 1px;
}

h1+h2, h2+h3 {
	margin-top: 0.83em;
}

p,
.mathjax-block {
	margin-top: 0;
	-webkit-hypens: auto;
	-moz-hypens: auto;
	hyphens: auto;
}
ul {
	list-style: square;
	padding-left: 1.2em;
}
ol {
	padding-left: 1.2em;
}
blockquote {
	margin-left: 1em;
	padding-left: 1em;
	border-left: 1px solid #ddd;
}
code,
pre {
	font-family: "Consolas", "Menlo", "Monaco", monospace, serif;
	font-size: .9em;
	background: white;
}
.md-fences{
	margin-left: 1em;
	padding-left: 1em;
	border: 1px solid #ddd;
	padding-bottom: 8px;
	padding-top: 6px;
	margin-bottom: 1.5em;
}

a {
	color: #2484c1;
	text-decoration: none;
}
a:hover {
	text-decoration: underline;
}
a img {
	border: none;
}
h1 a,
h1 a:hover {
	color: #333;
	text-decoration: none;
}
hr {
	color: #ddd;
	height: 1px;
	margin: 2em 0;
	border-top: solid 1px #ddd;
	border-bottom: none;
	border-left: 0;
	border-right: 0;
}
.ty-table-edit {
	background: #ededed;
    padding-top: 4px;
}
table {
	margin-bottom: 1.333333rem
}
table th,
table td {
	padding: 8px;
	line-height: 1.333333rem;
	vertical-align: top;
	border-top: 1px solid #ddd
}
table th {
	font-weight: bold
}
table thead th {
	vertical-align: bottom
}
table caption+thead tr:first-child th,
table caption+thead tr:first-child td,
table colgroup+thead tr:first-child th,
table colgroup+thead tr:first-child td,
table thead:first-child tr:first-child th,
table thead:first-child tr:first-child td {
	border-top: 0
}
table tbody+tbody {
	border-top: 2px solid #ddd
}

.task-list{
	padding:0;
}

.md-task-list-item {
	padding-left: 1.6rem;
}

.md-task-list-item > input:before {
	content: '\221A';
	display: inline-block;
	width: 1.33333333rem;
  	height: 1.6rem;
	vertical-align: middle;
	text-align: center;
	color: #ddd;
	background-color: #fefefe;
}

.md-task-list-item > input:checked:before,
.md-task-list-item > input[checked]:before{
	color: inherit;
}
.md-tag {
	color: inherit;
	font: inherit;
}
#write pre.md-meta-block {
	min-height: 35px;
	padding: 0.5em 1em;
}
#write pre.md-meta-block {
	white-space: pre;
	background: #f8f8f8;
	border: 0px;
	color: #999;
	
	width: 100vw;
	max-width: calc(100% + 60px);
	margin-left: -30px;
	border-left: 30px #f8f8f8 solid;
	border-right: 30px #f8f8f8 solid;

	margin-bottom: 2em;
	margin-top: -1.3333333333333rem;
	padding-top: 26px;
	padding-bottom: 10px;
	line-height: 1.8em;
	font-size: 0.9em;
	font-size: 0.76em;
	padding-left: 0;
}
.md-img-error.md-image>.md-meta{
	vertical-align: bottom;
}
#write>h5.md-focus:before {
	top: 2px;
}

.md-toc {
	margin-top: 40px;
}

.md-toc-content {
	padding-bottom: 20px;
}

.outline-expander:before {
	color: inherit;
	font-size: 14px;
	top: auto;
	content: "\f0da";
	font-family: FontAwesome;
}

.outline-expander:hover:before,
.outline-item-open>.outline-item>.outline-expander:before {
  	content: "\f0d7";
}

/** source code mode */
#typora-source {
	font-family: Courier, monospace;
    color: #6A6A6A;
}

.html-for-mac #typora-sidebar {
    -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, .175);
    box-shadow: 0 6px 12px rgba(0, 0, 0, .175);
}

.cm-s-typora-default .cm-header, 
.cm-s-typora-default .cm-property,
.CodeMirror.cm-s-typora-default div.CodeMirror-cursor {
	color: #428bca;
}

.cm-s-typora-default .cm-atom, .cm-s-typora-default .cm-number {
	color: #777777;
}

.typora-node .file-list-item-parent-loc, 
.typora-node .file-list-item-time, 
.typora-node .file-list-item-summary {
	font-family: arial, sans-serif;
}

.md-task-list-item>input {
    margin-left: -1.3em;
    margin-top: calc(1rem - 12px);
}

.md-mathjax-midline {
	background: #fafafa;
}

.md-fences .code-tooltip {
	bottom: -2em !important;
}

.dropdown-menu .divider {
	border-color: #e5e5e5;
}


</style><title>fiammetta</title>
</head>
<body class='typora-export os-windows'><div class='typora-export-content'>
<div id='write'  class=''><h2 id='table-of-contents'><span>Table of Contents</span></h2><div class='md-toc' mdtype='toc'><p class="md-toc-content" role="list"><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n0"><a class="md-toc-inner" href="#table-of-contents">Table of Contents</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n3"><a class="md-toc-inner" href="#1-introduction">1. Introduction</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n7"><a class="md-toc-inner" href="#2-real-time-interactive-video-communication">2. Real-time Interactive Video Communication</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n17"><a class="md-toc-inner" href="#3-existing-efforts">3. Existing Efforts</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n33"><a class="md-toc-inner" href="#4-our-solution---fiammetta">4. Our Solution - Fiammetta</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n34"><a class="md-toc-inner" href="#41-overview">4.1 Overview</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n44"><a class="md-toc-inner" href="#42-feasibility-study">4.2 Feasibility Study</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n52"><a class="md-toc-inner" href="#7-performances">7. Performances</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n60"><a class="md-toc-inner" href="#8-whats-next">8. What's Next?</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n65"><a class="md-toc-inner" href="#references">References</a></span></p></div><h2 id='1-introduction'><span>1. Introduction</span></h2><p><span>Maximizing </span><strong><span>quality of experience (QoE)</span></strong><span> for </span><strong><span>interactive video streaming</span></strong><span> has been a long-standing challenge, as its delay-sensitive nature makes it more vulnerable to </span><strong><span>bandwidth fluctuations</span></strong><span>. While </span><strong><span>reinforcement learning (RL)</span></strong><span> has demonstrated great potential, existing works are either limited by fixed models or require enormous data/time for online adaptation, which struggle to fit time-varying and diverse network states. </span></p><p><span>In this essay, I will introduce our project </span><em><strong><span>Fiammetta</span></strong></em><span>, a </span><strong><span>meta-reinforcement-learning (Meta-RL) based congestion control algorithm</span></strong><span> that aims to tackle the above challenge. To begin with, we performed a large-scale measurement on the interactive video service of </span><em><strong><span>Tencent WeCom</span></strong></em><span> to study real-world network fluctuations. Surprisingly, our analysis shows that, compared to time-varying network metrics, </span><strong><span>network statistics exhibit noticeable short-term continuity</span></strong><span>, which offers opportunities for few-shot learning methods such as meta-learning. Building on short-term continuity, </span><em><span>Fiammetta</span></em><span> accumulates learning experiences through offline meta-training and enables fast online adaptation to changing network states through a few gradient updates. The results show that </span><em><span>Fiammetta</span></em><span> outperforms existing algorithms significantly, i</span><strong><span>mproving video bitrate by 3.6%-16.2% without increasing stalling rate</span></strong><span>. </span></p><p><span>The related paper I co-authored: </span><em><span>&quot;From Ember to Blaze: Swift Interactive Video Adaptation via Meta-Reinforcement Learning&quot;</span></em><span> will be published at </span><strong><span>INFOCOM&#39;23</span></strong><span> in this May.</span></p><h2 id='2-real-time-interactive-video-communication'><span>2. Real-time Interactive Video Communication</span></h2><p><span>Recent years have witnessed the emergence of ultralow-latency interactive video applications, such as WeChat, Skype, Zoom, Facetime, etc. Especially with the outbreak of COVID-19 that bounds people with social distancing, the demand for digital classrooms, video conferences, e-commerce, etc. has increased substantially. Polaris Market reports that the global interactive video market is expected to reach $10.23 billion by 20281.</span></p><p><span>Despite the rapid development, the quality of experience (QoE) of interactive video streaming remains unsatisfactory. For example, blurry images and frequent stalling. It is because compared with VoD streaming, interactive video streaming is more vulnerable to varying network conditions for its low-latency requirement for the following reasons:</span></p><p><img src="./assets/Fiammetta-v2.jpg" referrerpolicy="no-referrer" alt="Fiammetta-v2"></p><ol start='' ><li><p><span>Unlike VoD streaming, where the client has a video buffer of serval seconds, the interactive video client has a </span><strong><span>limited video buffer of hundreds of milliseconds</span></strong><span>, which makes it more vulnerable to imperfect bandwidth estimations. </span></p></li><li><p><span>The limited codec buffer </span><strong><span>degrades the compression efficiency</span></strong><span>, and more bits are produced to be transmitted. </span></p></li></ol><p><span>How can we </span><strong><span>adapt the bitrate</span></strong><span> of an interactive video streaming system to </span><strong><span>varying network conditions</span></strong><span>?</span></p><h2 id='3-existing-efforts'><span>3. Existing Efforts</span></h2><p><strong><span>Congestion control (CC)</span></strong><span> algorithms are developed to adapt video-sending bitrate according to the estimated network capacity (bandwidth). The core part of CC is to model the network link and bandwidth estimation. Existing efforts could be categorized into </span><strong><span>rule-based CC</span></strong><span> and </span><strong><span>learning-based CC</span></strong><span>.</span></p><p><span>Rule-based CC algorithms such as </span><em><strong><span>GCC</span></strong></em><sup class='md-footnote'><a href='#dfref-footnote-1' name='ref-footnote-1'>1</a></sup><span> and </span><em><span>BBR</span></em><sup class='md-footnote'><a href='#dfref-footnote-2' name='ref-footnote-2'>2</a></sup><span>. They typically follow AIMD (additive-increase/multiplicative-decrease) / MIMD (multiplicative-increase/multiplicative-decrease)-like approaches that require a </span><strong><span>probing phase</span></strong><span> to converge sending bitrate to bandwidth. For instance, </span><em><span>GCC</span></em><span> iteratively estimates </span><em><span>bandwidth</span></em><span> and </span><em><span>one-way queuing delay</span></em><span> with a linear </span><em><span>Kalman Filter</span></em><span> (implemented in the &quot;Arrival filter&quot; in the following diagram), which assumes a static zero-mean Gaussian noise model.</span></p><p><img src="./assets/image-20230827160359753.png" alt="image-20230827160359753" style="zoom: 50%;" /></p><div align=center>
<center style="color:#808080">
	Google Congestion Control (GCC)
</center> 
</div><p><span>The drawbacks of this paradigm are two-fold:</span></p><ol start='' ><li><p><span>The application-layer video codec and transport-layer protocols are uncoordinated</span><sup class='md-footnote'><a href='#dfref-footnote-3' name='ref-footnote-3'>3</a></sup><span>. The bursty application-layer codec bitrate pattern (i.e., intermittent frame-by-frame delivery) often </span><strong><span>misleads the transport-layer’s network capacity estimation</span></strong><span>.</span></p></li><li><p><span>The probing phase suffers a slow convergence, leading to a </span><strong><span>low bandwidth utilization</span></strong><span>. Frequent </span><strong><span>change of the network state</span></strong><span> (handover in wireless networks, for instance) worsen the matter as the bottleneck link capacity and propagation delay change too fast for the prober to catch up.</span></p></li></ol><p><span>To tackle the first problem, learning-based congestion control</span><sup class='md-footnote'><a href='#dfref-footnote-3-1' name='ref-footnote-3-1'>3</a></sup><span> has been proposed. They replace the rule-based congestion control algorithms with </span><strong><span>deep reinforcement learning (DRL)</span></strong><span> models. However, they still suffer from the second problem imposed by fixed </span><strong><span>offline-learned</span></strong><span> neuron network parameters. </span></p><p><span>Recent studies</span><sup class='md-footnote'><a href='#dfref-footnote-4' name='ref-footnote-4'>4</a></sup><sup class='md-footnote'><a href='#dfref-footnote-5' name='ref-footnote-5'>5</a></sup><span> investigate the paradigm of </span><strong><span>online learning</span></strong><span>. Specifically, they fine-tune the offline learned model online with transfer learning to adapt to unseen network conditions. Nevertheless, they require a large amount of data/time for transfer learning, which hinders fast adaptation to new network states. </span></p><p><span>To better understand the dilemma, the following figure showcases a network trace with four network states:</span></p><p><img src="./assets/Fiammetta-v2-1693128608873-2.jpg" alt="Fiammetta-v2" style="zoom:50%;" /></p><p><span>The model trained offline may perform poorly in the middle two unseen states. With the aid of online learning, things are getting better, but still far from optimal due to the slow adaptation of transfer learning, For example, tens of minutes, even hours. We aim to </span><strong><span>adapt quickly to diverse and time-varying network states</span></strong><span>, pushing QoE to the limit. </span></p><h2 id='4-our-solution---fiammetta'><span>4. Our Solution - Fiammetta</span></h2><h3 id='41-overview'><span>4.1 Overview</span></h3><p><span>We resort to recent advances in few-shot adaptation methods such as </span><strong><span>meta-learning</span></strong><span>, more specifically, </span><strong><span>meta reinforcement learning (Meta-RL)</span></strong><span>, as no optimal bitrate is available in the training phase. This idea leads us to </span><em><strong><span>Fiammetta</span></strong></em><span>, a Meta-Reinforcement-Learning-based bitrate adaptation algorithm for interactive video systems.</span></p><p><em><span>Fiammetta</span></em><span> is based on </span><strong><span>model agnostic meta learning (MAML)</span></strong><span> framework, which consists of two phases: </span><em><span>meta-training</span></em><span> and </span><em><span>meta-testing</span></em><span>.</span></p><p>&nbsp;</p><p><img src="./assets/Fiammetta-v2-1693129629064-4.jpg" referrerpolicy="no-referrer" alt="Fiammetta-v2"></p><div align=center>
<center style="color:#808080">
	Meta-training
</center> 
</div><p><span>The goal of </span><em><span>the meta-training</span></em><span> phase is to obtain an initial model as a good starting point for further model adaptation. Specifically, the training consists of an inner loop and an outer loop. For every cycle of the outer loop update, a batch of </span><strong><span>tasks</span></strong><span> will be sampled from its prior distribution. Then, in the inner loop, the initial model interacts with a simulator given the generated traces of sampled tasks and is updated to maximize the pre-defined objective function. At the end of the inner loop, the gradients from all sampled tasks will be aggregated to update the initial model. Finally, </span><strong><span>meta-training provides better weight initialization</span></strong><span> for unseen new tasks.</span></p><p><img src="./assets/Fiammetta-v2-1693129810451-6.jpg" referrerpolicy="no-referrer" alt="Fiammetta-v2"></p><div align=center>
<center style="color:#808080">
	Meta-testing
</center> 
</div><p><span>In the </span><em><span>meta-testing</span></em><span> phase, the initial model adapts quickly to new tasks and generates a </span><strong><span>specialized sub-model</span></strong><span> with just a few gradient descents. It first </span><strong><span>identifies the appearance of new tasks.</span></strong><span> Once detected, it will activate meta-testing. Specifically, it generates network traces within the detected new task and updates the initial model to produce the sub-model accommodated to the new task, following the standard reinforcement learning pipeline. </span></p><h3 id='42-feasibility-study'><span>4.2 Feasibility Study</span></h3><p><span>Despite the potential of Meta-RL, one question remains: </span><strong><span>Is meta-learning fast enough to adapt?</span></strong><span> Typically, the adaptation process of meta-learning algorithms still requires several steps of gradient descent, which consumes 1 or 2 seconds on our server. Thus, we must first know how fast the real-world network state changes.</span></p><p><img src="./assets/Fiammetta-v2-1693130278373-8.jpg" alt="Fiammetta-v2" style="zoom:50%;" /></p><p><span>To investigate the characteristics of real-world network traces, we conduct a measurement study on a large-scale commercial network dataset collected by </span><strong><span>Tencent WeCom interactive video platform</span></strong><span>. The dataset consists of </span><strong><span>14,000</span></strong><span> real-world video sessions spanning around </span><strong><span>390 hours</span></strong><span>.</span></p><p><img src="./assets/Fiammetta-v2-1693130499535-10.jpg" alt="Fiammetta-v2" style="zoom:50%;" /></p><p><span>We first demonstrate how the instant bandwidth evolves during a time period of 1s and 4s (subfigure (a)). We can see that the bandwidth fluctuates drastically and is highly unpredictable. However, if we apply a sliding window on the traces and analyze their statistics, we notice that there exists </span><strong><span>short-term continuity</span></strong><span> in the statistics (subfigure (b)-(d)). For example, during a period of 4 seconds, both the mean and standard deviation vary less than 200 kbps in 90% of the cases. </span></p><p><span>We name the continuations as </span><em><span>network states</span></em><span>, which is the basic unit of our adaptation algorithm. The short-term continuity provides opportunities for meta-learning, where </span><strong><span>Meta-RL has the potential to keep up with the change of network states.</span></strong><span> </span></p><p><span>For the detailed design of </span><em><span>Fiammetta</span></em><span>, please refer to our </span><a href='https://github.com/WaterHyacinthInNANHU/WaterHyacinthInNANHU.github.io/blob/master/assets/pdf/Fiammetta.pdf'><span>paper</span></a><span>.</span></p><h2 id='7-performances'><span>7. Performances</span></h2><p><span>We build an end-to-end measurement testbed and exploit the real-world network traces sponsored by </span><strong><span>Tencent WeCom</span></strong><span> to test the performance of </span><em><span>Fiammetta</span></em><span> and baseline algorithms. Here is a quick glance at our system implementation and the testbed.</span></p><p><img src="./assets/Fiammetta-v2-1693131265849-12.jpg" referrerpolicy="no-referrer" alt="Fiammetta-v2"></p><p><span>The testbed mainly consists of two PCs running WebRTC as a video traffic transceiver pair and one PC controlling network link through the TC (traffic control) tool. Besides, we implement </span><em><span>Fiammetta</span></em><span> and learning-based baseline algorithms on a remote RL server, and the video transceiver pair is connected to the RL server via an additional router to query the target bitrate. The RL server is a desktop equipped with an Intel Core i7-9700K CPU, Geforce RTX 1080Ti GPU, and 32 GB memory. </span></p><p><img src="./assets/image-20230827181613402.png" referrerpolicy="no-referrer" alt="image-20230827181613402"></p><p><span>We start by showing the overall performances. We can see that </span><em><span>Fiammetta</span></em><span> improves QoE by </span><strong><span>11.1%, 17.0%, and 26.7%</span></strong><span> compared with OnRL</span><strong><span>,</span></strong><span> Loki and GCC, respectively. </span></p><p><img src="./assets/image-20230827181641330.png" referrerpolicy="no-referrer" alt="image-20230827181641330"></p><p><span>We further investigate its performance under different network conditions. The results show that </span><em><span>Fiammetta</span></em><span> consistently outperforms baseline methods across different network conditions.</span></p><h2 id='8-whats-next'><span>8. What&#39;s Next?</span></h2><p><strong><span>Fairness Concern</span></strong></p><p><span>In this work, we considered a simplified scenario where </span><em><span>Fiammetta</span></em><span> operates alone in the network link. In real-world deployment, </span><strong><span>fairness (receiving a no larger share of the network than other flows)</span></strong><span> against TCP connections and other video sessions is essential to a good CC algorithm.</span></p><p><strong><span>Computational Overhead</span></strong></p><p><span>In our framework, the computation of </span><em><span>Fiammetta</span></em><span> is offloaded to an RL server following the practice of previous works </span><sup class='md-footnote'><a href='#dfref-footnote-4-1' name='ref-footnote-4-1'>4</a></sup><span>. However, our collaborators in Tencent suggested that a more efficient and mobile-friendly algorithm is preferred. A potential solution is integrating </span><strong><span>low-cost rule-based algorithms with high-performance learning-based algorithms</span></strong><span> </span><sup class='md-footnote'><a href='#dfref-footnote-6' name='ref-footnote-6'>6</a></sup><span> . We may delve into it in our future works.</span></p><h2 id='references'><span>References</span></h2><p>&nbsp;</p><div class='footnotes-area'  ><hr/>
<div class='footnote-line'><span class='md-fn-count'>1</span> <span>Gaetano Carlucci, Luca De Cicco, Stefan Holmer, and Saverio Mascolo. 2016. Analysis and design of the google congestion control for web real-time communication (WebRTC). In Proceedings of the 7th International Conference on Multimedia Systems (MMSys &#39;16). Association for Computing Machinery, New York, NY, USA, Article 13, 1–12. </span><a href='https://doi.org/10.1145/2910017.2910605' target='_blank' class='url'>https://doi.org/10.1145/2910017.2910605</a> <a name='dfref-footnote-1' href='#ref-footnote-1' title='back to document' class='reversefootnote' >↩</a></div>
<div class='footnote-line'><span class='md-fn-count'>2</span> <span>Neal Cardwell, Yuchung Cheng, C. Stephen Gunn, Soheil Hassas Yeganeh, and Van Jacobson. 2016. BBR: Congestion-Based Congestion Control: Measuring bottleneck bandwidth and round-trip propagation time. Queue 14, 5 (September-October 2016), 20–53. </span><a href='https://doi.org/10.1145/3012426.3022184' target='_blank' class='url'>https://doi.org/10.1145/3012426.3022184</a> <a name='dfref-footnote-2' href='#ref-footnote-2' title='back to document' class='reversefootnote' >↩</a></div>
<div class='footnote-line'><span class='md-fn-count'>3</span> <span>Anfu Zhou, Huanhuan Zhang, Guangyuan Su, Leilei Wu, Ruoxuan Ma, Zhen Meng, Xinyu Zhang, Xiufeng Xie, Huadong Ma, and Xiaojiang Chen. 2019. Learning to Coordinate Video Codec with Transport Protocol for Mobile Video Telephony. In The 25th Annual International Conference on Mobile Computing and Networking (MobiCom &#39;19). Association for Computing Machinery, New York, NY, USA, Article 29, 1–16. </span><a href='https://doi.org/10.1145/3300061.3345430' target='_blank' class='url'>https://doi.org/10.1145/3300061.3345430</a> <a name='dfref-footnote-3' href='#ref-footnote-3' title='back to document' class='reversefootnote' >↩</a> <a name='dfref-footnote-3-1' href='#ref-footnote-3-1' title='back to document' class='reversefootnote' >↩</a></div>
<div class='footnote-line'><span class='md-fn-count'>4</span> <span>Huanhuan Zhang, Anfu Zhou, Jiamin Lu, Ruoxuan Ma, Yuhan Hu, Cong Li, Xinyu Zhang, Huadong Ma, and Xiaojiang Chen. OnRL: improving mobile video telephony via online reinforcement learning. In Proceedings of the 26th Annual International Conference on Mobile Computing and Networking, pages 1–14, 2020.</span> <a name='dfref-footnote-4' href='#ref-footnote-4' title='back to document' class='reversefootnote' >↩</a> <a name='dfref-footnote-4-1' href='#ref-footnote-4-1' title='back to document' class='reversefootnote' >↩</a></div>
<div class='footnote-line'><span class='md-fn-count'>5</span> <span>Huanhuan Zhang, Anfu Zhou, Yuhan Hu, Chaoyue Li, Guangping Wang, Xinyu Zhang, Huadong Ma, Leilei Wu, Aiyun Chen, and Changhui Wu. Loki: improving long tail performance of learning-based real-time video adaptation by fusing rule-based models. In Proceedings of the 27th Annual International Conference on Mobile Computing and Networking, pages 775–788, 2021</span> <a name='dfref-footnote-5' href='#ref-footnote-5' title='back to document' class='reversefootnote' >↩</a></div>
<div class='footnote-line'><span class='md-fn-count'>6</span> <span>Soheil Abbasloo, Chen-Yu Yen, and H. Jonathan Chao. 2020. Classic Meets Modern: a Pragmatic Learning-Based Congestion Control for the Internet. In Proceedings of the Annual conference of the ACM Special Interest Group on Data Communication on the applications, technologies, architectures, and protocols for computer communication (SIGCOMM &#39;20). Association for Computing Machinery, New York, NY, USA, 632–647. </span><a href='https://doi.org/10.1145/3387514.3405892' target='_blank' class='url'>https://doi.org/10.1145/3387514.3405892</a> <a name='dfref-footnote-6' href='#ref-footnote-6' title='back to document' class='reversefootnote' >↩</a></div></div></div></div>
</body>
</html>