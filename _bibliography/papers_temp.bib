---
---

@article{chan2021salkg,
  abbr={MM'23},
  title={Think before You Leap: Content-Aware Low-Cost Edge-Assisted Video Semantic Segmentation},
  author={Yan, Mingxuan and Yi, Wang and Xuedou, Xiao and Zhiqing, Luo and Jianhua, He and Wei Wang},
  journal={ACM International Conference on Multimedia (MM),},
  year={2023},
  doi={10.1145/3581783.3613808},
  html={https://doi.org/10.1145/3581783.3613808},
  pdf={Penance.pdf},
  selected={true},
}

@article{ma2021dss,
  abbr={NPJ Digit Med},
  title={Dissection Gesture Sequence during Nerve Sparing Predicts Erectile Function Recovery after Robot-Assisted Radical Prostatectomy},
  author={Ma, Runzhuo and Xu, Jiashu and Rodriguez, Ivan and DeMeo, Gina and Desai, Aditya and Trinh, Loc and Nguyen, H., Jessica and Anandkumar, Anima and Hu, C., Jim and Hung, J., Andrew},
  journal={NPJ Digit Medicine},
  html={/files/Dissection_Gesture_Abstract_v6.pdf},
  year={2022},
  selected={false},
}


@article{ma2021dart,
  abbr={AUA},
  title={Dissection Assessment for Robotic Technique (DART) to Evaluate Nerve-Spare of Robot-Assisted Radical Prostatectomy},
  author={Ma, Runzhuo and Hui, Alvin and Xu, Jiashu and Desai, Aditya and Tzeng, Michael and Cheng, Emily and Trinh, Loc and Nguyen, H., Jessica and Anandkumar, Anima and Hu, C., Jim and Hung, J., Andrew},
  journal={American Urological Association Annual Conference (AUA),},
  html={/files/DART_v5.pdf},
  pdf={https://www.auajournals.org/doi/10.1097/JU.0000000000002607.01},
  year={2022},
  selected={false},
}

@inproceedings{huang-etal-2022-unified,
    title = {Unified Semantic Typing with Meaningful Label Inference},
    author = {Huang, James Y. and Li*, Bangzheng and Xu*, Jiashu and Chen, Muhao},
    booktitle = {Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
    year = {2022},
    abbr={NAACL},
    preview={unist.jpg},
    arxiv={2205.01826},
    pdf={https://aclanthology.org/2022.naacl-main.190.pdf},
    abstract={Semantic typing aims at classifying tokens or spans of interest in a textual context into semantic categories such as relations, entity types, and event types. The inferred labels of semantic categories meaningfully interpret how machines understand components of text. In this paper, we present UniST, a unified framework for semantic typing that captures label semantics by projecting both inputs and labels into a joint semantic embedding space. To formulate different lexical and relational semantic typing tasks as a unified task, we incorporate task descriptions to be jointly encoded with the input, allowing UniST to be adapted to different tasks without introducing task-specific model components. UniST optimizes a margin ranking loss such that the semantic relatedness of the input and labels is reflected from their embedding similarity. Our experiments demonstrate that UniST achieves strong performance across three semantic typing tasks: entity typing, relation classification and event typing. Meanwhile, UniST effectively transfers semantic knowledge of labels and substantially improves generalizability on inferring rarely seen and unseen types. In addition, multiple semantic typing tasks can be jointly trained within the unified framework, leading to a single compact multi-tasking model that performs comparably to dedicated single-task models, while offering even better transferability.},
    selected = {true},
}

@COMMENT{ge2022dall,
  abbr={Arxiv},
  title={Dall-e for detection: Language-driven context image synthesis for object detection},
  author={Ge, Yunhao and Xu, Jiashu and Zhao, Brian Nlong and Itti, Laurent and Vineet, Vibhav},
  journal={arXiv preprint},
  arxiv={2206.09592},
  year={2022}
}

@inproceedings{ge2022neural,
  title={Neural-Sim: Learning to Generate Training Data with NeRF},
  author={Ge, Yunhao and Behl*, Harkirat and Xu*, Jiashu and Gunasekar, Suriya and Joshi, Neel and Song, Yale and Wang, Xin and Itti, Laurent and Vineet, Vibhav},
  booktitle={European Conference on Computer Vision (ECCV)},
  abbr={ECCV2022},
  pdf={https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136830463.pdf},
  arxiv={2207.11368},
  year={2022}
}

@article{xu2022can,
  abbr={Arxiv},
  title={Can NLI Provide Proper Indirect Supervision for Low-resource Biomedical Relation Extraction?},
  author={Xu, Jiashu and Ma, Mingyu Derek and Chen, Muhao},
  journal={arXiv preprint},
  arxiv={2212.10784},
  year={2022}
}